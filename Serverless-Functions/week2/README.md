# Bitcamp-Serverless
## **Week 2**

Last week, you should've learned the basics of how to create an Azure Function, along with the basics of triggers and bindings.

### **Learning Objectives**

- Parsing multipart data + Outputting in JSON
- Installing npm dependencies
- Making HTTP requests with fetch
- Working with the Face API + Reading its documentation
- Calling and Testing API Endpoints ft. Postman

### **Livestream**

In the livestream, we're going to code a HTTP trigger Azure Function that detects facial hair in a submitted picture.

- For the full video, look in the [video folder](https://github.com/emsesc/bitcamp-serverless/blob/master/week2/livestream/videos).
- For the full code, look in the [code folder](https://github.com/emsesc/bitcamp-serverless/blob/master/week2/livestream/code).

**We'll be going over how to:**

1. configure npm dependencies in Functions
2. parse multipart form data
3. create a Face API resource
4. make a HTTP request to the Face API
5. test the function using Postman

### Homework
Create a HTTP trigger Azure Function that uses the Face API to analyze emotion in a picture. 
- The step by step runthrough is located in the [issues folder](homework/issues). Follow the issues numerically to complete the project. 
- Any starter and solution code is in the [code folder](homework/code) in homework.

### :question: How will this help students?

The Week 2 livestream shows how to create an HTTP trigger that outputs facial hair information: close, but not quite what students have to do for homework. Because the demonstration is not exactly what the students are coding (an emotion reader), it gives them a chance to figure out some aspects of the project on their own. In addition to this, the livestream shows another example of how the Face API and HTTP trigger can be used.
